apiVersion: apps/v1
kind: Deployment
metadata:
  name: service_name    # service_name to be replaced with the uniqueId of the project
  labels:
    app: service_name
spec:
  replicas: 1
  selector:
    matchLabels:
      app: service_name
  template:
    metadata:
      labels:
        app: service_name
    spec:
      volumes:
        - name: workspace-volume    # to bring the initial base code from R2 and even after refresh by user, it will be present in the volume as we continously push the code to R2
          emptyDir: {}
      initContainers:
        - name: copy-s3-resources
          image: bitnami/aws-cli:latest
          command: ["/bin/sh", "-c"]
          args:
            - |
              # base code prefix is templated at runtime
              rm -rf /workspace/* /workspace/.* 2>/dev/null || true
              # Copy base code excluding .git folder and .git-archive.tar.gz
              aws s3 cp "s3://${R2_BUCKET_NAME}/BASE_CODE_PREFIX" /workspace/ --recursive --endpoint-url ${R2_ENDPOINT} --exclude "*.git*" --exclude "*.git-archive.tar.gz"
              echo "Base code copied from S3"
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_SECRET_ACCESS_KEY
            - name: R2_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_ENDPOINT
            - name: R2_BUCKET_NAME
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_BUCKET_NAME
          volumeMounts:
            - name: workspace-volume 
              mountPath: /workspace
        - name: restore-git-repository
          image: bitnami/aws-cli:latest
          command: ["/bin/sh", "-c"]
          args:
            - |
              # Restore Git repository from archive if it exists
              R2_ENDPOINT="${R2_ENDPOINT}"
              BUCKET_NAME="${R2_BUCKET_NAME}"
              ARCHIVE_KEY="Project_Code/${PROJECT_ID}/.git-archive.tar.gz"
              echo "Checking for Git archive at: s3://$BUCKET_NAME/$ARCHIVE_KEY"
              
              # Ensure tar is available in this image
              if ! command -v tar >/dev/null 2>&1; then
                echo "tar is not installed, attempting to install..."
                (apk add --no-cache tar gzip 2>/dev/null || \
                 microdnf install -y tar gzip 2>/dev/null || \
                 yum install -y tar gzip 2>/dev/null || \
                 apt-get update && apt-get install -y tar gzip 2>/dev/null) || true
              fi
              
              if aws s3 ls "s3://$BUCKET_NAME/$ARCHIVE_KEY" --endpoint-url "$R2_ENDPOINT" 2>/dev/null; then
                echo "Git archive found, restoring repository..."
                aws s3 cp "s3://$BUCKET_NAME/$ARCHIVE_KEY" /tmp/.git-archive.tar.gz --endpoint-url "$R2_ENDPOINT"
                cd /workspace
                if command -v tar >/dev/null 2>&1; then
                  tar -xzf /tmp/.git-archive.tar.gz
                  rm -f /tmp/.git-archive.tar.gz
                  if [ -d "/workspace/.git" ]; then
                    echo "Git repository restored successfully"
                    ls -la .git/
                  else
                    echo "Failed to restore .git directory even after extraction"
                    exit 1
                  fi
                else
                  echo "tar is still unavailable; cannot extract Git archive"
                  exit 1
                fi
              else
                echo "No Git archive found for project ${PROJECT_ID}, skipping Git restoration"
              fi
          env:
            - name: PROJECT_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.labels['app']
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_SECRET_ACCESS_KEY
            - name: R2_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_ENDPOINT
            - name: R2_BUCKET_NAME
              valueFrom:
                secretKeyRef:
                  name: server-credentials
                  key: R2_BUCKET_NAME       
          volumeMounts:
            - name: workspace-volume 
              mountPath: /workspace
      containers:
        - name: runner
          image: RUNNER_IMAGE    # templated at runtime
          ports:
            - containerPort: 3000   # for terminal,chats,other stuffs
            - containerPort: 3001   # for preview
          env:   # Only needed if runner needs some envs
            - name: WORKER_URL
              value: "http://localhost:3002"
            - name: PORT
              value: "3000"
            - name: WORKSPACE_PATH
              value: "/workspace"
            - name: BACKEND_URL
              value: "http://localhost:4000/api/v1"
            - name: DOMAIN
              value: "codevo.live"
          volumeMounts:
            - name: workspace-volume
              mountPath: /workspace
          resources:
            requests:
              cpu: "1"
              memory: "500Mi"
              ephemeral-storage: "500Mi"
            limits:
              cpu: "1"
              memory: "500Mi"
              ephemeral-storage: "500Mi"
        # This container will be accessed by end user
        - name: worker
          image: extremecoder01/worker    #change here
          ports:
            - containerPort: 3002
          envFrom:
            - secretRef:
                name: worker-env-secret
                   #change here
                # run below command to create the secret in CLI
                # kubectl create secret generic worker-env-secret --from-env-file=.env
          volumeMounts:
            - name: workspace-volume
              mountPath: /workspace
          resources:
            requests:
              cpu: "1"
              memory: "500Mi"
              ephemeral-storage: "500Mi" 
            limits:
              cpu: "1"
              memory: "500Mi"
              ephemeral-storage: "500Mi"

---
apiVersion: v1
kind: Service
metadata:
  name: service_name  # ← Must be same as projectId
spec:
  clusterIP: None  # ← This makes it a headless service
  selector:
    app: service_name
  ports:
    - protocol: TCP
      name: user    # will give access to runner
      port: 3000
      targetPort: 3000
    - protocol: TCP
      name: preview    # will give access to runner
      port: 3001
      targetPort: 3001


---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata: 
  name: service_name
  annotations:
    kubernetes.io/ingress.class: "nginx"  
    nginx.ingress.kubernetes.io/proxy-http-version: "1.1"
    nginx.ingress.kubernetes.io/websocket-services: preview-service
    nginx.ingress.kubernetes.io/enable-cors: 'true'
    nginx.ingress.kubernetes.io/cors-allow-origin: '*'
    nginx.ingress.kubernetes.io/cors-allow-methods: 'GET, POST, PUT, DELETE, OPTIONS'
    nginx.ingress.kubernetes.io/cors-allow-headers: 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization'
    # nginx.ingress.kubernetes.io/proxy-read-timeout: '3600'
    # nginx.ingress.kubernetes.io/proxy-send-timeout: '3600'
    # nginx.ingress.kubernetes.io/proxy-connect-timeout: '3600'
    nginx.ingress.kubernetes.io/websocket-services: 'true'
    nginx.ingress.kubernetes.io/enable-websocket: 'true'
    nginx.ingress.kubernetes.io/enable-cors: 'true'
    nginx.ingress.kubernetes.io/cors-allow-origin: '*'
    nginx.ingress.kubernetes.io/cors-allow-methods: 'GET, POST, PUT, DELETE, OPTIONS'
    nginx.ingress.kubernetes.io/cors-allow-headers: 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization'
    nginx.ingress.kubernetes.io/ssl-redirect: 'true'
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - service_name.codevo.live
      secretName: codevo-tls-secret
  rules:
  - host: service_name.codevo.live     # change here for local development
    http:
      paths:
      - path: /user/socket.io
        pathType: Prefix
        backend:
          service:
            name: service_name
            port:
              number: 3000
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: service_name
            port:
              number: 3000
      - path: /preview
        pathType: Prefix
        backend:
          service:
            name: service_name         
            port:
              number: 3000 
      - path: /
        pathType: Prefix
        backend:
          service:
            name: service_name          
            port:
              number: 3001  

      